{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[START] Test run 42965789d56540949889bf6b7b291ddf. Begin at 2022-03-01T14:57:03.399725\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "run_uuid = uuid.uuid4().hex\n",
    "start_time = str(datetime.now().isoformat())\n",
    "\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "p_use_db = True\n",
    "p_purge_db = False\n",
    "CONNECTION_STRING = \"mongodb://admin:admin@localhost:27018/?authSource=admin\"\n",
    "p_db = 'facial_indexer_3'\n",
    "p_face_collection = 'embeddings'\n",
    "p_profile_collection = 'profiles'\n",
    "\n",
    "p_resume = False\n",
    "\n",
    "p_do_split_dataset = False\n",
    "p_dataset_ratio = [0.8, 0.2]\n",
    "p_split_seed = 2022\n",
    "orig_path = '../tests/nguoinoitiengtv_redo/full'\n",
    "split_path = '../tests/nguoinoitiengtv_redo/split'\n",
    "train_path = os.path.join(split_path, 'train')\n",
    "val_path = os.path.join(split_path, 'val')\n",
    "\n",
    "# Parameters\n",
    "p_models = [\"VGG-Face\", \"Facenet\", \"Facenet512\", \"OpenFace\", \"DeepFace\", \"DeepID\", \"ArcFace\", \"Dlib\"]\n",
    "p_model = \"Facenet\"\n",
    "CNN_OUTPUT_SIZE = 128\n",
    "CNN_INPUT_SIZE = (160, 160)\n",
    "\n",
    "p_backends = ['opencv', 'ssd', 'dlib', 'mtcnn', 'retinaface', 'mediapipe', 'skip']\n",
    "p_detector_backend = 'mtcnn'\n",
    "\n",
    "p_grayscale = False\n",
    "p_enforce_detection = True\n",
    "\n",
    "p_metrics = ['euclidean', 'cosine']\n",
    "p_metric = 'cosine'\n",
    "p_normalize_vectors = True\n",
    "p_cuda_index = False\n",
    "\n",
    "p_consensus_test_upper_inclusive = 32\n",
    "\n",
    "p_export_folder = f'../results/{run_uuid}/'\n",
    "p_export_json_class2pid = os.path.join(p_export_folder, f'train_class2pid.json')\n",
    "p_export_json_train_faces = os.path.join(p_export_folder, f'train_faces.json')\n",
    "p_export_json_train_profiles = os.path.join(p_export_folder, f'train_profiles.json')\n",
    "p_export_json_val_faces = os.path.join(p_export_folder, f'val_faces.json')\n",
    "p_export_json_faiss_kneighbors = os.path.join(p_export_folder, f'val_faiss_k32_neighbors.json')\n",
    "p_export_bin_faiss_index = os.path.join(p_export_folder, f'faiss_index.bin')\n",
    "\n",
    "p_result_eval = os.path.join(p_export_folder, f'eval.csv')\n",
    "p_result_accuracy = os.path.join(p_export_folder, f'accuracy.csv')\n",
    "\n",
    "p_tensorflow_export = os.path.join(p_export_folder, f'{p_model}_{start_time.replace(\":\", \"\").replace(\".\", \"\")}')\n",
    "\n",
    "if not os.path.exists(p_export_folder):\n",
    "    os.makedirs(p_export_folder)\n",
    "\n",
    "print(f\"[START] Test run {run_uuid}. Begin at {start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preparation: 80-20 split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `splitfolders` to split dataset into training and validation set with customizable ratio and seed\n",
    "\n",
    "Here, 80-20 is chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitfolders\n",
    "\n",
    "if p_do_split_dataset:\n",
    "    splitfolders.ratio(\n",
    "        orig_path, output=split_path, seed=p_split_seed, ratio=(p_dataset_ratio[0], p_dataset_ratio[1])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Dataset Description\n",
      "           pic_count\n",
      "count  12586.000000\n",
      "mean       4.288177\n",
      "std        1.059748\n",
      "min        2.000000\n",
      "25%        3.000000\n",
      "50%        5.000000\n",
      "75%        5.000000\n",
      "max       12.000000 \n",
      "sum\t53971\n",
      "Train Dataset Description\n",
      "           pic_count\n",
      "count  12586.000000\n",
      "mean       3.217464\n",
      "std        0.960474\n",
      "min        1.000000\n",
      "25%        2.000000\n",
      "50%        4.000000\n",
      "75%        4.000000\n",
      "max        9.000000 \n",
      "sum\t40495\n",
      "Validation Dataset Description\n",
      "           pic_count\n",
      "count  12586.000000\n",
      "mean       1.070713\n",
      "std        0.256666\n",
      "min        1.000000\n",
      "25%        1.000000\n",
      "50%        1.000000\n",
      "75%        1.000000\n",
      "max        3.000000 \n",
      "sum\t13476\n",
      "53971 == 40495 + 13476\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def get_dataset_stat(base_path):\n",
    "    name_series = []\n",
    "    count_series = []\n",
    "\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        if not dirs:\n",
    "            person_name = root.split('/')[-1]\n",
    "            img_count = len(files)\n",
    "\n",
    "            name_series.append(person_name)\n",
    "            count_series.append(img_count)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'name': name_series,\n",
    "        'pic_count': count_series\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "full_stat = get_dataset_stat(orig_path)\n",
    "train_stat = get_dataset_stat(train_path)\n",
    "val_stat = get_dataset_stat(val_path)\n",
    "\n",
    "full_sum = full_stat['pic_count'].sum()\n",
    "train_sum = train_stat['pic_count'].sum()\n",
    "val_sum = val_stat['pic_count'].sum()\n",
    "\n",
    "print(\"Full Dataset Description\\n\", full_stat.describe(), f\"\\nsum\\t{full_sum}\")\n",
    "print(\"Train Dataset Description\\n\", train_stat.describe(), f\"\\nsum\\t{train_sum}\")\n",
    "print(\"Validation Dataset Description\\n\", val_stat.describe(), f\"\\nsum\\t{val_sum}\")\n",
    "\n",
    "print(f'{full_sum} {\"==\" if full_sum == train_sum + val_sum else \"!=\"} {train_sum} + {val_sum}')\n",
    "\n",
    "if full_sum != train_sum + val_sum:\n",
    "    input(\"[ERROR] Dataset count mismatch. Stop process and recreate dataset to avoid wrong results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Facial Embedding vectors and Database insertions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather image path and group by class (profile) into a `dict{type, name, images}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Imported 12588 profiles from JSON file\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open( os.path.join(orig_path, '../profiles_redo.json'), 'r' ) as f:\n",
    "    profiles = json.load(f)\n",
    "\n",
    "print(f\"[INFO] Imported {len(profiles)} profiles from JSON file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Train Dataset: Copied 12588 profiles and added path prefix for 40495 train image paths\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "train_profiles = []\n",
    "train_images_count = 0\n",
    "\n",
    "for profile in profiles:\n",
    "    profile_copy = deepcopy(profile)\n",
    "    # Pop old image paths without prefix\n",
    "    images = profile_copy.pop('images', None)\n",
    "    \n",
    "    # new empty array\n",
    "    images_with_prefix = []\n",
    "    for img in images:\n",
    "        new_path = (os.path.join(train_path, *img.split('/')[1:]))\n",
    "        if os.path.exists(new_path) == True:\n",
    "            images_with_prefix.append(new_path)\n",
    "            train_images_count += 1\n",
    "    profile_copy['images'] = images_with_prefix\n",
    "\n",
    "    train_profiles.append(profile_copy)\n",
    "\n",
    "print(f\"[INFO] Train Dataset: Copied {len(train_profiles)} profiles and added path prefix for {train_images_count} train image paths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create truth table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Create truth mapping table from 53971 images and 12588 profiles\n"
     ]
    }
   ],
   "source": [
    "img2pid_truth = {}\n",
    "for profile in profiles:\n",
    "    for image in profile['images']:\n",
    "        head, tail = os.path.split(image)\n",
    "        value = profile['_id']\n",
    "        img2pid_truth[tail] = value\n",
    "\n",
    "print(f\"[INFO] Create truth mapping table from {len(img2pid_truth)} images and {len(profiles)} profiles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FacialIndex instance (Facenet + FAISS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FacialIndex instance created with the following parameters and variables: \n",
      " model_name=Facenet\n",
      " face_detector_backend=mtcnn\n",
      " face_enforce_detection=True\n",
      " faiss_use_cuda=False\n",
      " faiss_index_type=cosine\n",
      " faiss_vector_normalize=True\n",
      " use_db=True  at mongodb://admin:admin@localhost:27018/?authSource=admin, dbname=facial_indexer_3\n",
      " profile_counter=0, face_counter=0 index size: 0\n"
     ]
    }
   ],
   "source": [
    "from facialindex.facialindex import FacialIndex\n",
    "\n",
    "fi = FacialIndex(\n",
    "    model_name=p_model,\n",
    "    face_detector_backend=p_detector_backend,\n",
    "    face_enforce_detection=p_enforce_detection,\n",
    "    faiss_use_cuda=p_cuda_index,\n",
    "    faiss_index_type=p_metric,\n",
    "    faiss_vector_normalize=p_normalize_vectors,\n",
    "    use_db=p_use_db,\n",
    "    mongodb_client=CONNECTION_STRING,\n",
    "    db_name=p_db\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add Profiles and Faces to Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding Subjects and Faces to index: 100%|██████████| 20/20 [01:14<00:00,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 20 profiles with 62 faces processed.\n",
      "[INFO] 0 profiles dropped due to having found no faces in any of the images.\n",
      "[INFO] 3 images dropped in total due to having found no faces.\n",
      "[INFO] 20 profiles with 62 faces inserted to index. Current index size 62\n",
      "[SUCCESS] Inserted 20 profiles and 62 faces to db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if p_resume == True:\n",
    "    faces_out = fi.get_cached_faces()\n",
    "    profiles_out = fi.get_cached_profiles()\n",
    "else:\n",
    "    faces_out, profiles_out = fi.add_profiles(train_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(f'Faces: {sys.getsizeof(faces_out)}B\\nProfiles: {sys.getsizeof(profiles_out)}B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "\n",
    "for root, dirs, files in os.walk(val_path):\n",
    "    if not dirs:\n",
    "        person_name = root.split('/')[-1]\n",
    "\n",
    "        for file in files:\n",
    "            img_path = root + '/' + file\n",
    "            paths.append(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing face query with FAISS index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from facialindex.error import FacialIndexError, ImagePreprocessFaceError\n",
    "\n",
    "# key = validation image unique identification\n",
    "# value = array of [ measure, embedding id, profile id ] sorted by measure of most similar\n",
    "val_faiss_k_neighbors = {}\n",
    "val_found_no_face_count = 0\n",
    "\n",
    "for path in tqdm( paths ):\n",
    "    try:\n",
    "        measures, neighbors = fi.query_face_faiss(path, k=p_consensus_test_upper_inclusive)\n",
    "    except ImagePreprocessFaceError:\n",
    "        val_found_no_face_count += 1\n",
    "        continue\n",
    "\n",
    "    # matches = face_collection.find(\n",
    "    #     { \"_id\": { \"$in\": [f\"face_{idnum}\" for idnum in neighbors[0].tolist()] } },\n",
    "    #     { \"profile_id\": 1 }\n",
    "    # )\n",
    "    # matches = list(matches) \n",
    "\n",
    "    matches = [faces_out[f'embedding_{idnum}'] for idnum in neighbors.tolist()]\n",
    "\n",
    "    results = [ [ np.float64(distance), match['_id'], match['profile_id'] ] for match, distance in zip(matches, measures) ]\n",
    "\n",
    "    spl = path.split('/')\n",
    "    short_key = f'{spl[-1]}'\n",
    "    val_faiss_k_neighbors[short_key] = results\n",
    "\n",
    "print(f\"[INFO] Created validation image query results mapping. {val_found_no_face_count} images dropped due to having found no face. Length = {len(val_faiss_k_neighbors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create result tracking dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# series of validation image unique id\n",
    "val_paths2 = []\n",
    "# series of validation image classname\n",
    "val_classnames = []\n",
    "# series of validation image truth profile_id\n",
    "val_truth_pid = []\n",
    "for path in paths: \n",
    "    spl = path.split('/')\n",
    "    val_paths2.append('{}'.format(spl[-1]))\n",
    "    val_classnames.append(spl[-2])\n",
    "    val_truth_pid.append( img2pid_truth[spl[-1]] )\n",
    "\n",
    "import pandas as pd\n",
    "eval_df = pd.DataFrame(\n",
    "    { \n",
    "        \"truth_class\": val_classnames,\n",
    "        \"truth_pid\": val_truth_pid\n",
    "    },\n",
    "    index=val_paths2\n",
    ")\n",
    "\n",
    "for i in range( 1, p_consensus_test_upper_inclusive + 1 ):\n",
    "    eval_df[f'predict_{i}'] = np.nan \n",
    "    eval_df[f'positive_{i}'] = np.nan\n",
    "\n",
    "print(\"[INFO] Created results tracking dataframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Consensus for k=[1,25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode \n",
    "def get_consensus(result_arr, top_k=[ None ]):\n",
    "    distances, embeddings, profiles = list( zip(*result_arr) )\n",
    "    \n",
    "    ret = ()\n",
    "    for k in top_k:\n",
    "        ret = ret + ( mode(profiles[0:k]), )\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the validation image query results mapping\n",
    "# and append the prediction result for k from 1 to n to the result tracking dataframe\n",
    "for key, value in val_faiss_k_neighbors.items():\n",
    "    predictions = get_consensus( value,  list(range( 1, p_consensus_test_upper_inclusive + 1 )) )\n",
    "    eval_df.at[key, 'predicted'] = True\n",
    "    for n in range( 1, p_consensus_test_upper_inclusive + 1 ):\n",
    "        eval_df.at[key, f'predict_{n}'] = predictions[n - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set positive_n columns\n",
    "for n in range( 1, p_consensus_test_upper_inclusive + 1 ):\n",
    "    eval_df[f'positive_{n}'] = np.where( (eval_df['truth_pid'] == eval_df[f'predict_{n}']), True, False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count = eval_df[ eval_df['predicted'] == True ].shape[0]\n",
    "total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_series = []\n",
    "positive_series = []\n",
    "\n",
    "for n in range( 1, p_consensus_test_upper_inclusive + 1 ):\n",
    "    k_positive_count = eval_df[ eval_df['truth_pid'] == eval_df[f'predict_{n}'] ].shape[0]\n",
    "    accuracy = k_positive_count/total_count\n",
    "    positive_series.append(k_positive_count)\n",
    "    accuracy_series.append(accuracy)\n",
    "    # print(n, k_positive_count, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(\n",
    "    { \n",
    "        \"positive\": positive_series,\n",
    "        \"accuracy\": accuracy_series,\n",
    "    },\n",
    "    index=list(range( 1, p_consensus_test_upper_inclusive + 1 ))\n",
    ")\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(p_export_folder):\n",
    "    os.makedirs(p_export_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(p_export_json_train_faces, 'w') as f:\n",
    "    json.dump(faces_out, f)\n",
    "\n",
    "with open(p_export_json_train_profiles, 'w') as f:\n",
    "    json.dump(profiles_out, f)\n",
    "\n",
    "print(f'Model output written. {len(faces_out)} and {len(profiles_out)} dictionary keys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.to_csv(p_result_eval)\n",
    "result_df.to_csv(p_result_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi.get_model().save(p_tensorflow_export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(p_export_json_class2pid, 'w') as f:\n",
    "    json.dump(img2pid_truth, f)\n",
    "\n",
    "print(\"ImageNameId-ProfileId map written to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(p_export_json_val_faces, 'w') as f:\n",
    "#     json.dump(val_emb, f)\n",
    "\n",
    "# print(\"Validation Face Embeddings: Written {} {}-length vectors\".format(len(val_emb), len(embedding)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(p_export_json_faiss_kneighbors, 'w') as f:\n",
    "    json.dump(val_faiss_k_neighbors, f)\n",
    "\n",
    "print(f\"Written {len(val_faiss_k_neighbors)} dicts, each with {p_consensus_test_upper_inclusive}x{CNN_OUTPUT_SIZE}-length vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "if p_cuda_index == True:\n",
    "    index_flat_cpu = faiss.index_gpu_to_cpu(fi.get_index())\n",
    "    faiss.write_index(index_flat_cpu, p_export_bin_faiss_index)\n",
    "else:\n",
    "    faiss.write_index(fi.get_index(), p_export_bin_faiss_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = str(datetime.now().isoformat())\n",
    "\n",
    "run_settings = {\n",
    "    'id': run_uuid,\n",
    "    'start': start_time,\n",
    "    'end': end_time,\n",
    "    'database': {\n",
    "        'use_database': p_use_db,\n",
    "        'purge_database': p_purge_db,\n",
    "        'connection_string': CONNECTION_STRING,\n",
    "        'database_name': p_db,\n",
    "        'profiles_collection': p_profile_collection,\n",
    "        'embeddings_collection': p_face_collection,\n",
    "    },\n",
    "    'dataset': {\n",
    "        'do_split_dataset': p_do_split_dataset,\n",
    "        'dataset_ratio': p_dataset_ratio,\n",
    "        'dataset_split_seed': p_split_seed,\n",
    "        'dataset_paths': {\n",
    "            'original': base_path,\n",
    "            'split_path': split_path,\n",
    "            'train_path': train_path,\n",
    "            'val_path': val_path,\n",
    "        },\n",
    "    },\n",
    "    'face_model': p_model,\n",
    "    'face_detector_backend': p_detector_backend,\n",
    "    'face_grayscale': p_grayscale,\n",
    "    'face_enforce_detection': p_enforce_detection,\n",
    "    'faiss_metric': p_metric,\n",
    "    'faiss_normalize_vectors': p_normalize_vectors,\n",
    "    'faiss_use_cuda': p_cuda_index,\n",
    "    'consensus_test_range': [1, p_consensus_test_upper_inclusive],\n",
    "    'exports': {\n",
    "        'root': p_export_folder,\n",
    "        'class2pid': p_export_json_class2pid,\n",
    "        'train_faces': p_export_json_train_faces,\n",
    "        'train_profiles': p_export_json_train_profiles,\n",
    "        'val_faces': p_export_json_val_faces,\n",
    "        'faiss_query_results': p_export_json_faiss_kneighbors,\n",
    "        'faiss_index': p_export_bin_faiss_index,\n",
    "        'results_compare_table': p_result_eval,\n",
    "        'results_accuracy_table': p_result_accuracy,\n",
    "        'tensorflow_export': p_tensorflow_export\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open( os.path.join(p_export_folder, 'params.json'), 'w' ) as f:\n",
    "    json.dump(run_settings, f)\n",
    "\n",
    "print(\"Written parameters to file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test Run {run_uuid} completed. From {start_time} to {end_time}. Results and Parameters stored at {p_export_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "################################################################################################\n",
    "################################################################################################\n",
    "################################################################################################"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
